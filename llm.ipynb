{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# llms - API"
      ],
      "metadata": {
        "id": "DcsWMmrSj08J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure API key\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# List available models\n",
        "models = genai.list_models()\n",
        "for model in models:\n",
        "    print(model.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ecTVCpvuj4uL",
        "outputId": "4dcfeeae-ad1d-47fd-f304-9942209304cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-preview\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "F9TeHTVPSbCA",
        "outputId": "18f97aee-9d10-4a4d-e03c-83b5630db741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is ML?\n",
            "Response: ML stands for **Machine Learning**.  It's a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.  Instead of being explicitly programmed, ML systems learn from data.\n",
            "\n",
            "In simpler terms, you feed a machine learning system lots of data, and it uses that data to identify patterns, make predictions, and improve its performance over time without being explicitly told how to do each task.\n"
          ]
        }
      ],
      "source": [
        "# Gemini API Demo\n",
        "# pip install google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure API key (for Colab)\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Initialize model\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Simple prompt\n",
        "prompt = \"What is ML?\"\n",
        "\n",
        "# Configure generation parameters\n",
        "generation_config = genai.types.GenerationConfig(\n",
        "    max_output_tokens=100,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40\n",
        ")\n",
        "\n",
        "# Generate response\n",
        "response = model.generate_content(prompt, generation_config=generation_config)\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Response: {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# example 2 : gemini"
      ],
      "metadata": {
        "id": "KF3P2tKhS4w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini API Demo\n",
        "# pip install google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure API key (for Colab)\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Initialize model\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Simple prompt\n",
        "prompt = \"What is a neural network?\"\n",
        "\n",
        "# Configure generation parameters\n",
        "generation_config = genai.types.GenerationConfig(\n",
        "    max_output_tokens=100,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40\n",
        ")\n",
        "\n",
        "# Generate response\n",
        "response = model.generate_content(prompt, generation_config=generation_config)\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Response: {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "2Yj8FLdjS6N8",
        "outputId": "ecb1c63e-ce2f-40fd-ac62-451f3a13f471"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is a neural network?\n",
            "Response: A neural network is a computing system inspired by the biological neural networks that constitute animal brains.  It's a complex interconnected web of simple processing units, called **neurons** or **nodes**, organized in layers.  These layers typically include:\n",
            "\n",
            "* **Input layer:** Receives the initial data (e.g., pixels in an image, words in a sentence).\n",
            "* **Hidden layers:** Perform complex transformations on the data.  A network can have multiple hidden layers, increasing its capacity to\n"
          ]
        }
      ]
    }
  ]
}